{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf5RrhNaDejC"
   },
   "source": [
    "# An offline demo for the \"Learning-based Video Motion Magnification\" (ECCV 2018)\n",
    "\n",
    "# Official repo: https://github.com/12dmodel/deep_motion_mag\n",
    "# My repo: https://github.com/ZhengPeng7/motion_magnification_learning-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make sure to set your python Kernel for notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7Ghq0laIGq4"
   },
   "source": [
    "## Preparations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWvGFo9yECoa"
   },
   "source": [
    "### Install python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nI-Hq9WK5xNg",
    "outputId": "4c55ba46-ee51-4752-8dd1-deab4ffe704e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --quiet -r requirements.txt\n",
    "!pip install --quiet gdown mediapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhA7-odZEHQW"
   },
   "source": [
    "### Download and load the well-trained weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUX3pb77Axr0",
    "outputId": "11164c11-73dc-4418-8248-dfb9ab66d535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\n",
      "ERROR: could not open HSTS store at '/root/.wget-hsts'. HSTS will be disabled.\n",
      "--2023-11-05 14:03:48--  https://github.com/ZhengPeng7/motion_magnification_learning-based/releases/download/v1.0/magnet_epoch12_loss7.28e-02.pth\n",
      "Resolving github.com (github.com)... 47.93.241.142, 39.106.83.44\n",
      "Connecting to github.com (github.com)|47.93.241.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/223970988/4e613b00-aa97-11ea-87b4-bef43fcc6281?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231105T060349Z&X-Amz-Expires=300&X-Amz-Signature=054d40cd1599fce311358e5952e84073f9d390e242c658cc5a3de30142350113&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223970988&response-content-disposition=attachment%3B%20filename%3Dmagnet_epoch12_loss7.28e-02.pth&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-05 14:03:49--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/223970988/4e613b00-aa97-11ea-87b4-bef43fcc6281?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231105T060349Z&X-Amz-Expires=300&X-Amz-Signature=054d40cd1599fce311358e5952e84073f9d390e242c658cc5a3de30142350113&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=223970988&response-content-disposition=attachment%3B%20filename%3Dmagnet_epoch12_loss7.28e-02.pth&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3528201 (3.4M) [application/octet-stream]\n",
      "Saving to: ‘magnet_epoch12_loss7.28e-02.pth’\n",
      "\n",
      "magnet_epoch12_loss 100%[===================>]   3.36M  15.3KB/s    in 3m 17s  \n",
      "\n",
      "2023-11-05 14:07:09 (17.5 KB/s) - ‘magnet_epoch12_loss7.28e-02.pth’ saved [3528201/3528201]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/ZhengPeng7/motion_magnification_learning-based/releases/download/v1.0/magnet_epoch12_loss7.28e-02.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "quAf0VARHAPM",
    "outputId": "7eb23fde-56e9-4797-dd0a-091b559aaec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please load train_mf.txt if you want to do training.\n",
      "Loading weights: magnet_epoch12_loss7.28e-02.pth\n"
     ]
    }
   ],
   "source": [
    "from magnet import MagNet\n",
    "from callbacks import gen_state_dict\n",
    "from config import Config\n",
    "\n",
    "\n",
    "# config\n",
    "config = Config()\n",
    "# Load weights\n",
    "weights_path = 'magnet_epoch12_loss7.28e-02.pth'\n",
    "ep = int(weights_path.split('epoch')[-1].split('_')[0])\n",
    "state_dict = gen_state_dict(weights_path)\n",
    "\n",
    "model_test = MagNet().cuda()\n",
    "model_test.load_state_dict(state_dict)\n",
    "model_test.eval()\n",
    "print(\"Loading weights:\", weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AM4n9P-iaNG"
   },
   "source": [
    "# Preprocess\n",
    "\n",
    "Make the video to frameAs/frameBs/frameCs.\n",
    "\n",
    "Let's take the guitar.mp4 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnJSrX43vlgy",
    "outputId": "bb3fec89-a7f1-4246-a4c7-7f08548ca905"
   },
   "outputs": [],
   "source": [
    "# Download some example video from my google-drive or upload your own video.\n",
    "# !gdown 1hNZ02vnSO04FYS9jkx2OjProYHIvwdkB  # guitar.avi\n",
    "!gdown 1XGC2y4Lshd9aBiBxwkTuT_IA79n-WNST  # baby.avi\n",
    "# !gdown 1QGOWuR0swF7_eHharTztlkEDz0hlfmU4  # zhiyin.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pd9lV4mCHU9v"
   },
   "source": [
    "# Set VIDEO_NAME here, e.g., guitar, baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0v0Uacfmtib",
    "outputId": "01383531-8a69-42f5-8b7c-a280acff41c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.3 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7.3.0 (crosstool-NG 1.23.0.449-a04d0)\n",
      "  configuration: --prefix=/opt/conda/conda-bld/ffmpeg_1597178665428/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placeh --cc=/opt/conda/conda-bld/ffmpeg_1597178665428/_build_env/bin/x86_64-conda_cos6-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-pic --enable-pthreads --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libmp3lame\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "Input #0, avi, from 'baby.avi':\n",
      "  Duration: 00:00:10.03, start: 0.000000, bitrate: 15411 kb/s\n",
      "    Stream #0:0: Video: mjpeg (Baseline) (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 960x544 [SAR 1:1 DAR 30:17], 15399 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x561bdb17b380] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, image2, to 'baby/%06d.png':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: png, rgb24, 960x544 [SAR 1:1 DAR 30:17], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 png\n",
      "frame=  301 fps= 48 q=-0.0 Lsize=N/A time=00:00:10.03 bitrate=N/A speed= 1.6x    \n",
      "video:187776kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "ACB-Processing on baby\n"
     ]
    }
   ],
   "source": [
    "# Turn the video into frames and make them into frame_ACB format.\n",
    "file_to_be_maged = 'baby.avi'   # 'guitar.avi'\n",
    "video_name = file_to_be_maged.split('.')[0]\n",
    "video_format = '.' + file_to_be_maged.split('.')[-1]\n",
    "\n",
    "\n",
    "sh_file = 'VIDEO_NAME={}\\nVIDEO_FORMAT={}'.format(video_name, video_format) + \"\"\"\n",
    "\n",
    "\n",
    "mkdir ${VIDEO_NAME}\n",
    "ffmpeg -i ${VIDEO_NAME}${VIDEO_FORMAT} -f image2 ${VIDEO_NAME}/%06d.png\n",
    "python make_frameACB.py ${VIDEO_NAME}\n",
    "mkdir test_dir\n",
    "mv ${VIDEO_NAME} test_dir\n",
    "\"\"\"\n",
    "with open('test_preproc.sh', 'w') as file:\n",
    "  file.write(sh_file)\n",
    "\n",
    "!bash test_preproc.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeOYfifiGUPq"
   },
   "source": [
    "## Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXz3mYanz07-",
    "outputId": "9d526b43-6f76-404c-fa91-235ea6b5ee72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test image couples: 300\n",
      "100, 200, 300, res_baby/baby/baby_amp10.avi has been done.\n",
      "100, 200, 300, res_baby/baby/baby_amp25.avi has been done.\n",
      "100, 200, 300, res_baby/baby/baby_amp50.avi has been done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from data import get_gen_ABC, unit_postprocessing, numpy2cuda, resize2d\n",
    "\n",
    "\n",
    "# testsets = '+'.join(['baby', 'guitar', 'gun', 'drone', 'cattoy', 'water'][:])\n",
    "for testset in [video_name]:\n",
    "    dir_results = 'res_' + testset\n",
    "    if not os.path.exists(dir_results):\n",
    "        os.makedirs(dir_results)\n",
    "\n",
    "    config.data_dir = 'test_dir'\n",
    "    data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "    print('Number of test image couples:', data_loader.data_len)\n",
    "    vid_size = cv2.imread(data_loader.paths[0]).shape[:2][::-1]\n",
    "\n",
    "    # Test\n",
    "    for amp in [10, 25, 50]:\n",
    "        frames = []\n",
    "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "        for idx_load in range(0, data_loader.data_len, data_loader.batch_size):\n",
    "            if (idx_load+1) % 100 == 0:\n",
    "                print('{}'.format(idx_load+1), end=', ')\n",
    "            batch_A, batch_B = data_loader.gen_test()\n",
    "            amp_factor = numpy2cuda(amp)\n",
    "            for _ in range(len(batch_A.shape) - len(amp_factor.shape)):\n",
    "                amp_factor = amp_factor.unsqueeze(-1)\n",
    "            with torch.no_grad():\n",
    "                y_hats = model_test(batch_A, batch_B, 0, 0, amp_factor, mode='evaluate')\n",
    "            for y_hat in y_hats:\n",
    "                y_hat = unit_postprocessing(y_hat, vid_size=vid_size)\n",
    "                frames.append(y_hat)\n",
    "                if len(frames) >= data_loader.data_len:\n",
    "                    break\n",
    "            if len(frames) >= data_loader.data_len:\n",
    "                break\n",
    "        data_loader = get_gen_ABC(config, mode='test_on_'+testset)\n",
    "        frames = [unit_postprocessing(data_loader.gen_test()[0], vid_size=vid_size)] + frames\n",
    "\n",
    "        # Make videos of framesMag\n",
    "        video_dir = os.path.join(dir_results, testset)\n",
    "        if not os.path.exists(video_dir):\n",
    "            os.makedirs(video_dir)\n",
    "        FPS = 30\n",
    "        video_save_path = os.path.join(video_dir, '{}_amp{}{}'.format(testset, amp, video_format))\n",
    "        out = cv2.VideoWriter(\n",
    "            video_save_path,\n",
    "            cv2.VideoWriter_fourcc(*'DIVX'),\n",
    "            FPS, frames[0].shape[-2::-1]\n",
    "        )\n",
    "        for frame in frames:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            cv2.putText(frame, 'amp_factor={}'.format(amp), (7, 37),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 0, 255), thickness=2)\n",
    "            out.write(frame)\n",
    "        out.release()\n",
    "        print('{} has been done.'.format(video_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the amplified video here\n",
    "from glob import glob\n",
    "import mediapy\n",
    "\n",
    "\n",
    "video_save_paths = [file_to_be_maged] + sorted(glob(os.path.join(dir_results, testset, '*')), key=lambda x: int(x.split('amp')[-1].split('.')[0]))\n",
    "\n",
    "video_dict = {}\n",
    "for video_save_path in video_save_paths[:]:\n",
    "  video_dict[video_save_path.split('/')[-1]] = mediapy.read_video(video_save_path)\n",
    "mediapy.show_videos(video_dict, fps=FPS, width=250, codec='gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
